{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Canceled future for execute_request message before replies were done",
     "output_type": "error",
     "traceback": [
      "Error: Canceled future for execute_request message before replies were done",
      "at t.KernelShellFutureHandler.dispose (c:\\Users\\Asus\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1204175)",
      "at c:\\Users\\Asus\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1223227",
      "at Map.forEach (<anonymous>)",
      "at v._clearKernelState (c:\\Users\\Asus\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1223212)",
      "at v.dispose (c:\\Users\\Asus\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:1216694)",
      "at c:\\Users\\Asus\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:533674",
      "at t.swallowExceptions (c:\\Users\\Asus\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:913059)",
      "at dispose (c:\\Users\\Asus\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:533652)",
      "at t.RawSession.dispose (c:\\Users\\Asus\\.vscode\\extensions\\ms-toolsai.jupyter-2022.3.1000901801\\out\\extension.js:2:537330)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (node:internal/process/task_queues:96:5)"
     ]
    }
   ],
   "source": [
    "# os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "from collections import deque\n",
    "import random\n",
    "# random_seed = 0\n",
    "# random.seed(random_seed)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "import traci\n",
    "import sumolib\n",
    "from ray.rllib.env.multi_agent_env import MultiAgentEnv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from traffic_signal_Onnut import TrafficSignal\n",
    "\n",
    "# if 'SUMO_HOME' in os.environ:\n",
    "#     tools = os.path.join(os.environ['SUMO_HOME'], 'tools')\n",
    "#     sys.path.append(tools)\n",
    "# else:\n",
    "#     sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "from gym import spaces\n",
    "import gym\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "# from dqn import Network\n",
    "\n",
    "\n",
    "# from buffer import Buffer\n",
    "# from madqn import maDQN\n",
    "# from env_Onnut import SumoEnvironment\n",
    "# import gym\n",
    "import time\n",
    "\n",
    "class Buffer:\n",
    "    def __init__(self,n_agents,buffer_size,batch_size):\n",
    "        self.n_agents = n_agents\n",
    "        self.batch_size = batch_size\n",
    "        self.replay_buffers = []\n",
    "        for agent_idx in n_agents:\n",
    "            self.replay_buffers.append(deque(maxlen=buffer_size))\n",
    "\n",
    "    def store(self,transition):\n",
    "        i = 0\n",
    "        for agent_idx in self.n_agents:\n",
    "            # print(agent_idx)\n",
    "            # obs = transition[0][agent_idx]\n",
    "            # actions = transition[1][agent_idx]\n",
    "            # rewards = transition[2][agent_idx]\n",
    "            # dones = transition[3][agent_idx]\n",
    "            # new_obs = transition[4][agent_idx]\n",
    "\n",
    "            obs = transition.get((agent_idx,'obs'))\n",
    "            actions = transition.get((agent_idx,'actions'))\n",
    "            rewards = transition.get((agent_idx,'rewards'))\n",
    "            dones = transition.get((agent_idx,'dones'))\n",
    "            new_obs = transition.get((agent_idx,'new_obs'))\n",
    "\n",
    "            agent_transition = (obs, actions, rewards, dones, new_obs)\n",
    "            self.replay_buffers[i].append(agent_transition)\n",
    "            i+=1\n",
    "\n",
    "    def sample(self):\n",
    "        samples = []\n",
    "        for agent_idx in range(len(self.n_agents)):\n",
    "            samples.append(random.sample(self.replay_buffers[agent_idx], self.batch_size))\n",
    "        return samples\n",
    "\n",
    "\n",
    "class SumoEnvironment(MultiAgentEnv):\n",
    "    \"\"\"\n",
    "    SUMO Environment for Traffic Signal Control\n",
    "\n",
    "    :param net_file: (str) SUMO .net.xml file\n",
    "    :param phases: (traci.trafficlight.Phase list) Traffic Signal phases definition\n",
    "    :param out_csv_name: (str) name of the .csv output with simulation results. If None no output is generated\n",
    "    :param use_gui: (bool) Wheter to run SUMO simulation with GUI visualisation\n",
    "    :param num_seconds: (int) Number of simulated seconds on SUMO\n",
    "    :param delta_time: (int) Simulation seconds between actions\n",
    "    :param min_green: (int) Minimum green time in a phase\n",
    "    :param max_green: (int) Max green time in a phase\n",
    "    :single_agent: (bool) If true, it behaves like a regular gym.Env. Else, it behaves like a MultiagentEnv (https://github.com/ray-project/ray/blob/master/python/ray/rllib/env/multi_agent_env.py)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, net_file, out_csv_name=None, use_gui=False, num_seconds=68400,\n",
    "                 time_to_teleport=900, delta_time=15, yellow_time=0, min_green=15\n",
    "                 , max_green_onnut=135, max_green_virtual=30, single_agent=False):\n",
    "\n",
    "        self._net = net_file\n",
    "        self.use_gui = use_gui\n",
    "        if self.use_gui:\n",
    "            self._sumo_binary = sumolib.checkBinary('sumo-gui')\n",
    "        else:\n",
    "            self._sumo_binary = sumolib.checkBinary('sumo')\n",
    "\n",
    "        self.sim_max_time = num_seconds\n",
    "        self.delta_time = delta_time  # seconds on sumo at each step\n",
    "        self.begin_time = 54000\n",
    "        self.time_to_teleport = time_to_teleport\n",
    "        self.min_green = min_green\n",
    "        # max_green_onnut = 135,\n",
    "        # max_green_virtual =  30,\n",
    "        self.max_green_onnut = max_green_onnut\n",
    "        self.max_green_virtual = max_green_virtual\n",
    "        self.max_green =  {'cluster_1088409501_272206263_5136790697_70702637':max_green_onnut,'gneJ42':max_green_virtual}\n",
    "        self.yellow_time = yellow_time\n",
    "        # self.random_number = random_number\n",
    "\n",
    "        traci.start([sumolib.checkBinary('sumo'), '-n', self._net])  # start only to retrieve information\n",
    "\n",
    "        self.single_agent = single_agent\n",
    "        self.ts_ids = ['cluster_1088409501_272206263_5136790697_70702637','gneJ42']\n",
    "        self.ts_junction = {'cluster_1088409501_272206263_5136790697_70702637':'ONNUT','gneJ42':'VIRTUAL'}\n",
    "        self.traffic_signals = {ts: TrafficSignal(self,\n",
    "                                                  ts,\n",
    "                                                  self.delta_time,\n",
    "                                                  self.yellow_time,\n",
    "                                                  self.min_green,\n",
    "                                                  self.max_green[ts],\n",
    "                                                  self.begin_time,\n",
    "                                                  self.ts_junction[ts]) for ts in self.ts_ids}\n",
    "\n",
    "        self.observations = {ts: None for ts in self.ts_ids}\n",
    "        self.rewards = {ts: None for ts in self.ts_ids}\n",
    "        self.teleport_numbers = 0\n",
    "        self.reward_range = (-float('inf'), float('inf'))\n",
    "        self.run = 0\n",
    "        self.metrics = []\n",
    "        self.out_csv_name = out_csv_name\n",
    "        traci.close()\n",
    "\n",
    "    def save_score(self):\n",
    "        self.save_csv(self.out_csv_name, self.run)\n",
    "        self.run += 1\n",
    "\n",
    "    def save_score_max_green(self):\n",
    "        self.save_csv_max_green(self.out_csv_name, self.run, self.max_green_onnut, self.max_green_virtual)\n",
    "        self.run += 1\n",
    "\n",
    "    def reset(self,random_seed):\n",
    "        if self.run != 0:\n",
    "            traci.close()\n",
    "            # self.save_csv(self.out_csv_name, self.run)\n",
    "        # self.run += 1\n",
    "        self.metrics = []\n",
    "\n",
    "        traci.start([self._sumo_binary,\n",
    "                     '-n', self._net,\n",
    "                     '-c', \"onnut_ake.sumocfg\",\n",
    "                     '--time-to-teleport', str(self.time_to_teleport),\n",
    "                     '--start', 'true',\n",
    "                     '--quit-on-end','true',\n",
    "                     \"--no-internal-links\",'true',\n",
    "                     \"--ignore-junction-blocker\",'-1',\n",
    "                     '--no-warnings', 'true',\n",
    "                     '--seed', str(random_seed),\n",
    "                     ])\n",
    "\n",
    "        self.traffic_signals = {ts: TrafficSignal(self,\n",
    "                                                  ts,\n",
    "                                                  self.delta_time,\n",
    "                                                  self.yellow_time,\n",
    "                                                  self.min_green,\n",
    "                                                  self.max_green[ts],\n",
    "                                                  self.begin_time,\n",
    "                                                  self.ts_junction[ts]) for ts in self.ts_ids}\n",
    "\n",
    "\n",
    "        if self.single_agent:\n",
    "            return self._compute_observations()[self.ts_ids[0]]\n",
    "        else:\n",
    "            return self._compute_observations()\n",
    "\n",
    "    @property\n",
    "    def sim_step(self):\n",
    "        \"\"\"\n",
    "        Return current simulation second on SUMO\n",
    "        \"\"\"\n",
    "        return traci.simulation.getTime()\n",
    "\n",
    "    def step(self, action):\n",
    "        # No action, follow fixed TL defined in self.phases\n",
    "        if action is None or action == {}:\n",
    "            for _ in range(self.delta_time):\n",
    "                self._sumo_step()\n",
    "                if self.sim_step % 15 == 0:\n",
    "                    info = self._compute_step_info()\n",
    "                    self.metrics.append(info)\n",
    "        else:\n",
    "            self._apply_actions(action)\n",
    "\n",
    "            time_to_act = False\n",
    "\n",
    "            #---- Reset reward for new timestep ----#\n",
    "            self.rewards[self.ts_ids[0]] = 0\n",
    "            self.rewards[self.ts_ids[1]] = 0\n",
    "\n",
    "            self.teleport_numbers = 0\n",
    "\n",
    "            # i = 0\n",
    "            while not time_to_act:\n",
    "                self._sumo_step()\n",
    "\n",
    "                rewards = self._compute_rewards()\n",
    "                for k, v in rewards.items():\n",
    "                    temp = self.rewards.get(k)\n",
    "                    if temp == None:\n",
    "                        temp = 0\n",
    "                    self.rewards[k] = temp+v\n",
    "\n",
    "                teleport_number = self._compute_teleports()\n",
    "                if teleport_number == None :\n",
    "                    teleport_number = 0\n",
    "                self.teleport_numbers += teleport_number\n",
    "\n",
    "                # for k, v in teleport_number.items():\n",
    "                #     temp = self.teleport_numbers.get(k)\n",
    "                #     if temp == None:\n",
    "                #         temp = 0\n",
    "                #     self.teleport_numbers[k] = temp+v\n",
    "\n",
    "                for ts in self.ts_ids:\n",
    "                    self.traffic_signals[ts].update()\n",
    "                    if self.traffic_signals[ts].time_to_act:\n",
    "                        time_to_act = True\n",
    "\n",
    "                if self.sim_step % 15 == 0:\n",
    "                    info = self._compute_step_info()\n",
    "                    self.metrics.append(info)\n",
    "\n",
    "        observations = self._compute_observations()\n",
    "        # rewards = self._compute_rewards()\n",
    "        done = {'__all__': self.sim_step > self.sim_max_time}\n",
    "        done.update({ts_id: False for ts_id in self.ts_ids})\n",
    "\n",
    "        if self.single_agent:\n",
    "            return observations[self.ts_ids[0]], self.rewards[self.ts_ids[0]], done['__all__'], {}\n",
    "        else:\n",
    "            return observations, self.rewards, done, {}\n",
    "\n",
    "    def _apply_actions(self, actions):\n",
    "        \"\"\"\n",
    "        Set the next green phase for the traffic signals\n",
    "        :param actions: If single-agent, actions is an int between 0 and self.num_green_phases (next green phase)\n",
    "                        If multiagent, actions is a dict {ts_id : greenPhase}\n",
    "        \"\"\"   \n",
    "        if self.single_agent:\n",
    "            self.traffic_signals[self.ts_ids[0]].set_next_phase(actions)\n",
    "        else:\n",
    "            for ts, action in actions.items():\n",
    "                self.traffic_signals[ts].set_next_phase(action)\n",
    "    \n",
    "    def _compute_observations(self):\n",
    "        self.observations.update({ts: self.traffic_signals[ts].compute_observation() for ts in self.ts_ids if self.traffic_signals[ts].time_to_act})\n",
    "        return {ts: self.observations[ts].copy() for ts in self.observations.keys() if self.traffic_signals[ts].time_to_act}\n",
    "\n",
    "    def _compute_rewards(self):\n",
    "        # return {ts: self.traffic_signals[ts].compute_reward() for ts in self.ts_ids if self.traffic_signals[ts].time_to_act}\n",
    "        return {ts: self.traffic_signals[ts].compute_reward() for ts in self.ts_ids}\n",
    "\n",
    "    def _compute_teleports(self):\n",
    "        # return {ts: self.traffic_signals[ts].compute_reward() for ts in self.ts_ids if self.traffic_signals[ts].time_to_act}\n",
    "        return self.traffic_signals[self.ts_ids[0]].compute_teleport()\n",
    "        # {ts: self.traffic_signals[ts].compute_teleport() for ts in self.ts_ids}\n",
    "\n",
    "    @property\n",
    "    def observation_space(self):\n",
    "        return self.traffic_signals[self.ts_ids[0]].observation_space\n",
    "    \n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return self.traffic_signals[self.ts_ids[0]].action_space\n",
    "    \n",
    "    def observation_spaces(self, ts_id):\n",
    "        return self.traffic_signals[ts_id].observation_space\n",
    "    \n",
    "    def action_spaces(self, ts_id):\n",
    "        return self.traffic_signals[ts_id].action_space\n",
    "\n",
    "    def _sumo_step(self):\n",
    "        traci.simulationStep()\n",
    "\n",
    "    def _compute_step_info(self):\n",
    "        return {\n",
    "            'step_time': self.sim_step,\n",
    "            'onnut_action': self.traffic_signals[self.ts_ids[0]].current_phase,\n",
    "            'virtual_action': self.traffic_signals[self.ts_ids[1]].current_phase,        \n",
    "            # 'reward_onnut': sum(self.traffic_signals[ts].compute_reward() for ts in self.ts_ids if self.traffic_signals[ts].time_to_act),\n",
    "            'reward_onnut' : self.rewards[self.ts_ids[0]],\n",
    "            'reward_virtual' : self.rewards[self.ts_ids[1]],\n",
    "            'total_travel_time_onnut' : self.traffic_signals[self.ts_ids[0]].get_travel_time(),\n",
    "            'total_travel_time_virtual' : self.traffic_signals[self.ts_ids[1]].get_travel_time(),\n",
    "            # 'total_travel_time_all' : self.traffic_signals[self.ts_ids[0]].get_travel_time_all()\n",
    "            'teleport_number' : self.teleport_numbers #doesn't care about teleport number\n",
    "        }\n",
    "\n",
    "    def close(self):\n",
    "        traci.close()\n",
    "\n",
    "    def save_csv(self, out_csv_name, run):\n",
    "        if out_csv_name is not None:\n",
    "            df = pd.DataFrame(self.metrics)\n",
    "            Path(Path(out_csv_name).parent).mkdir(parents=True, exist_ok=True)\n",
    "            df.to_csv(out_csv_name + '_run{}'.format(run) + '.csv', index=False)\n",
    "\n",
    "    def save_csv_max_green(self, out_csv_name, run, max_green_onnut, max_green_virtual):\n",
    "        if out_csv_name is not None:\n",
    "            df = pd.DataFrame(self.metrics)\n",
    "            Path(Path(out_csv_name).parent).mkdir(parents=True, exist_ok=True)\n",
    "            df.to_csv(out_csv_name + '_onnut{}'.format(max_green_onnut) +'_virtual{}'.format(max_green_virtual)+ '_run{}'.format(run) + '.csv', index=False)\n",
    "\n",
    "    def getTime(self,time):\n",
    "        time=time%(24*3600)\n",
    "        hours=time//3600\n",
    "        time%=3600\n",
    "        minutes=time//60\n",
    "        time%=60\n",
    "        seconds=time\n",
    "        periods=[('hours',int(hours)),('minutes',int(minutes)),('seconds',int(seconds))]\n",
    "        time_string=':'.join('{}'.format(value) for name,value in periods)\n",
    "        return time_string\n",
    "\n",
    "\n",
    "\n",
    "class TrafficSignal:\n",
    "    \"\"\"\n",
    "    This class represents a Traffic Signal of an intersection\n",
    "    It is responsible for retrieving information and changing the traffic phase using Traci API\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env, ts_id, delta_time, yellow_time, min_green, max_green, begin_time, junction):\n",
    "        self.id = ts_id\n",
    "        self.env = env\n",
    "        self.delta_time = delta_time\n",
    "        self.yellow_time = yellow_time\n",
    "        self.min_green = min_green\n",
    "        self.max_green = max_green\n",
    "        self.current_phase = 0\n",
    "        self.is_yellow = False\n",
    "        self.time_since_last_phase_change = 0\n",
    "        self.next_action_time = begin_time\n",
    "        self.last_measure = 0.0\n",
    "        self.last_reward = None\n",
    "\n",
    "        self.phases = traci.trafficlight.getCompleteRedYellowGreenDefinition(self.id)[0].phases\n",
    "        self.num_phases = len(self.phases)  # Number of green phases\n",
    "\n",
    "        #============ Indicate junction =========#\n",
    "        self.junction = junction  #Using for difference in junction\n",
    "        #========================================#\n",
    "\n",
    "\n",
    "        #self.observation_space = spaces.Box(low=np.zeros(self.num_phases + 1 + self.get_observation_places()), high=np.ones(self.num_phases + 1 +self.get_observation_places()), dtype=np.float32)\n",
    "\n",
    "        if self.junction == \"ONNUT\" :\n",
    "            self.observation_space = spaces.Box(low=np.zeros(self.num_phases + 1 + 18), high=np.ones(self.num_phases + 1 + 18), dtype=np.float32)\n",
    "        elif self.junction == \"VIRTUAL\" :\n",
    "            self.observation_space = spaces.Box(low=np.zeros(self.num_phases + 1 + 15), high=np.ones(self.num_phases + 1 + 15), dtype=np.float32)    \n",
    "\n",
    "        print('Observation space of ', junction,'is :', self.observation_space)\n",
    "        # print('>>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        self.action_space = spaces.Discrete(self.num_phases)\n",
    "        print('Action space of ', junction,'is :', self.action_space)\n",
    "\n",
    "        if self.junction == 'ONNUT' :\n",
    "            #SB,WB,NB\n",
    "            # ONNUT_UPSTREAM_DETECTOR_ID = 4,5,6,9,11,12\n",
    "            # ONNUT_DOWNSTREAM_DETECTOR_ID = 3,8,10\n",
    "\n",
    "            #Dict with key: indicate up/downstream , value: list of detectorID\n",
    "\n",
    "            self.SB_detectorID_dict = {\n",
    "            'UPSTREAM' :   [ \"S_ONT_04_0\",\"S_ONT_04_1\",\"S_ONT_04_2\",\n",
    "                             \"S_ONT_09_0\",\"S_ONT_09_1\",\"S_ONT_09_2\"] ,\n",
    "\n",
    "            'DOWNSTREAM' : [ \"S_ONT_03_0\",\"S_ONT_03_1\",\"S_ONT_03_2\",\n",
    "                             \"S_ONT_07_0\",\"S_ONT_07_1\",\"S_ONT_07_2\"]\n",
    "                                    }\n",
    "\n",
    "            self.WB_detectorID_dict = {\n",
    "            'UPSTREAM' : [\"S_ONT_05_0\",\"S_ONT_05_1\"],\n",
    "            'DOWNSTREAM' : [\"S_ONT_18_0\",\"S_ONT_18_1\"]\n",
    "                                    }\n",
    "\n",
    "            self.NB_detectorID_dict = {\n",
    "            'UPSTREAM' : [\n",
    "                    \"S_ONT_06_0\",\"S_ONT_06_1\",\"S_ONT_06_2\",\"S_ONT_06_3\",\n",
    "                    \"S_ONT_11_0\",\"S_ONT_11_1\",\"S_ONT_11_2\",\"S_ONT_11_3\",\n",
    "                    \"S_ONT_12_0\",\"S_ONT_12_1\",\"S_ONT_12_2\",\"S_ONT_12_3\"\n",
    "                                        ],\n",
    "            'DOWNSTREAM' : [\n",
    "                    \"S_ONT_08_0\",\n",
    "                    \"S_ONT_10_0\",\"S_ONT_10_1\",\"S_ONT_10_2\"\n",
    "                                            ]\n",
    "                                    }\n",
    "\n",
    "            self.loopID = [\n",
    "                'Induction_Loop_1','Induction_Loop_2','Induction_Loop_3',\n",
    "                'Induction_Loop_4','Induction_Loop_5','Induction_Loop_6',\n",
    "                'Induction_Loop_7','Induction_Loop_8','Induction_Loop_9','Induction_Loop_10' \n",
    "                        ]\n",
    "\n",
    "            self.edgeID_for_MOE = [\n",
    "                #NB\n",
    "                '824116560#0','824116560#1','824116560#2','824116560#3','824816455','220429932#0','824116561-AddedOffRampEdge','113135465#5',\n",
    "                '750035412#1-AddedOffRampEdge','824816456','113135465#0','113135465#2',\n",
    "                #SB\n",
    "                '751454884#3','751454884#2','751454884#0',\n",
    "                '751454885#0','751454885#2','751454885#3','751454885#5',\n",
    "                #WB\n",
    "                '824456410#0','824456410#2','824456410#2.41',\n",
    "                '156591171#2','-824456410#2','156591171#0'\n",
    "                                ]\n",
    "\n",
    "            # self.edgeID_all = traci.edge.getIDList()\n",
    "                \n",
    "        elif self.junction == \"VIRTUAL\" :\n",
    "\n",
    "            # SB, WB, BigC\n",
    "            #Dict with key: indicate up/downstream , value: list of detectorID\n",
    "            #VIRTUAL_UPSTREAM_DETECTOR_ID = 2,13,14,17\n",
    "            #VIRTUAL_DOWNSTREAM_DETECTOR_ID = 1,15,16\n",
    "\n",
    "            self.SB_detectorID_dict = {\n",
    "            'UPSTREAM' : [\n",
    "                    \"S_ONT_13_0\",\"S_ONT_13_1\",\n",
    "                    \"S_ONT_14_0\",\"S_ONT_14_1\",\n",
    "                                            ],\n",
    "            'DOWNSTREAM' : [\n",
    "                    \"S_ONT_15_0\",\"S_ONT_15_1\",\n",
    "                    \"S_ONT_16_0\",\"S_ONT_16_1\"\n",
    "                                            ]\n",
    "                                        }\n",
    "            self.WB_detectorID_dict = {\n",
    "            'UPSTREAM' : [\n",
    "                    \"S_ONT_02_0\",\"S_ONT_02_1\",\n",
    "                    \"S_ONT_13_0\",\"S_ONT_13_1\",\n",
    "                    \"S_ONT_14_0\",\"S_ONT_14_1\",\n",
    "                    \"S_ONT_17_0\"\n",
    "                                            ],\n",
    "            'DOWNSTREAM' : [\n",
    "                    \"S_ONT_01_0\",\"S_ONT_01_1\",\n",
    "                    \"S_ONT_15_0\",\"S_ONT_15_1\",\n",
    "                    \"S_ONT_16_0\",\"S_ONT_16_1\"\n",
    "                                            ]\n",
    "                                        }\n",
    "            self.BIGC_detectorID_dict = {\n",
    "            'UPSTREAM' : [\"S_ONT_17_0\"],\n",
    "            'DOWNSTREAM' : []\n",
    "                                        }\n",
    "\n",
    "            self.loopID = [\n",
    "                \"Virtual_loop_1\",\"Virtual_loop_2\",\"Virtual_loop_3\",\n",
    "                \"Virtual_loop_4\",\"Virtual_loop_5\"]\n",
    "            \n",
    "            self.edgeID_for_MOE = [\n",
    "                #SB\n",
    "                '824456410#2','824456410#2.41','824456409#0','-gneE25',\n",
    "                '-824456410#2','156591171#0','-824456409#0','-gneE24',\n",
    "                #WB\n",
    "                'gneE34','824456409#5','824456409#6','113135397#1','113135397#3',\n",
    "                'gneE33','-824456409#5','-113135397#0','-113135397#2','-113135397#4',\n",
    "                #BigC\n",
    "                'gneE32','gneE29'\n",
    "                                ]\n",
    "            # self.edgeID_all = []\n",
    "\n",
    "    @property\n",
    "    def phase(self):\n",
    "        return traci.trafficlight.getPhase(self.id)\n",
    "\n",
    "    @property\n",
    "    def time_to_act(self):\n",
    "        # print(self.next_action_time , self.env.sim_step,self.next_action_time == self.env.sim_step)\n",
    "        return self.next_action_time == self.env.sim_step\n",
    "\n",
    "    def update(self):\n",
    "        self.time_since_last_phase_change += 1\n",
    "\n",
    "    def set_next_phase(self, new_phase):\n",
    "        self.new_phase = new_phase\n",
    "        # print('*************************************************')\n",
    "        # print('tls id : ', self.id)\n",
    "        # print('current phase : ', self.phase)\n",
    "        # print('new phase :', self.new_phase)\n",
    "        # print('current sim time : ',self.env.sim_step)\n",
    "        # print('self.time_since_last_phase_change',self.time_since_last_phase_change)\n",
    "\n",
    "        if self.phase == self.new_phase and self.time_since_last_phase_change < self.min_green:\n",
    "            # print('current phase and agent\\'s action phase are equal but duration of current phase is less than min green time')\n",
    "            self.next_action_time = self.env.sim_step +  self.delta_time\n",
    "\n",
    "        elif self.phase == self.new_phase and self.time_since_last_phase_change >= self.min_green:\n",
    "            # print('current phase and agent\\'s action phase are equal, and still less than max green time')\n",
    "            self.next_action_time = self.env.sim_step + self.delta_time\n",
    "\n",
    "        elif self.phase == self.new_phase and self.time_since_last_phase_change > self.max_green:\n",
    "            # print('duration of current phase is over max_green now')\n",
    "            if self.new_phase +1 >=self.num_phases:\n",
    "                self.current_phase = 0\n",
    "            else:\n",
    "                self.current_phase = self.new_phase + 1\n",
    "\n",
    "            traci.trafficlight.setPhase(self.id, self.current_phase)\n",
    "            self.next_action_time = self.env.sim_step + self.delta_time\n",
    "            self.time_since_last_phase_change = 0\n",
    "\n",
    "        elif self.phase != self.new_phase and self.time_since_last_phase_change < self.min_green:\n",
    "            # print('current phase and agent\\'s action phase are not equal but duration of current phase is less than min green time')\n",
    "            self.next_action_time = self.env.sim_step +  self.delta_time\n",
    "\n",
    "        elif self.phase != self.new_phase and self.time_since_last_phase_change >= self.min_green:\n",
    "            # print('current phase and agent\\'s action phase are not equal, and duration is greater than min green time')\n",
    "            self.current_phase = self.new_phase\n",
    "            traci.trafficlight.setPhase(self.id, self.current_phase)\n",
    "            self.next_action_time = self.env.sim_step + self.delta_time\n",
    "            self.time_since_last_phase_change = 0\n",
    "        #######################################################\n",
    "\n",
    "        # print(self.next_action_time)\n",
    "\n",
    "\n",
    "    def compute_observation(self):\n",
    "        phase_id = [1 if self.current_phase == i else 0 for i in range(self.num_phases)]  # one-hot encoding\n",
    "        min_green = [0 if self.time_since_last_phase_change < self.min_green else 1]\n",
    "        UPSTREAM_OBS = []\n",
    "        DOWNSTREAM_OBS = []\n",
    "        if self.junction == \"ONNUT\" :\n",
    "            occu_SB_UP,occu_WB_UP,occu_NB_UP = self.get_occupancy_average_percent(indicate=\"UPSTREAM\")\n",
    "            flow_SB_UP,flow_WB_UP,flow_NB_UP = self.get_flow_sum(indicate=\"UPSTREAM\")\n",
    "            unjam_SB_UP,unjam_WB_UP,unjam_NB_UP = self.get_flow_sum(indicate=\"UPSTREAM\")\n",
    "\n",
    "            UPSTREAM_OBS = [occu_SB_UP,flow_SB_UP,unjam_SB_UP,\n",
    "                            occu_WB_UP,flow_WB_UP,unjam_WB_UP,\n",
    "                            occu_NB_UP,flow_NB_UP,unjam_NB_UP]\n",
    "\n",
    "            occu_SB_DOWN,occu_WB_DOWN,occu_NB_DOWN = self.get_occupancy_average_percent(indicate=\"DOWNSTREAM\")\n",
    "            flow_SB_DOWN,flow_WB_DOWN,flow_NB_DOWN = self.get_flow_sum(indicate=\"DOWNSTREAM\")\n",
    "            unjam_SB_DOWN,unjam_WB_DOWN,unjam_NB_DOWN = self.get_flow_sum(indicate=\"DOWNSTREAM\")\n",
    "\n",
    "            DOWNSTREAM_OBS = [occu_SB_DOWN,flow_SB_DOWN,unjam_SB_DOWN,\n",
    "                              occu_WB_DOWN,flow_WB_DOWN,unjam_WB_DOWN,\n",
    "                              occu_NB_DOWN,flow_NB_DOWN,unjam_NB_DOWN]\n",
    "\n",
    "        elif self.junction == \"VIRTUAL\" :\n",
    "            occu_SB_UP,occu_WB_UP,occu_BIGC_UP = self.get_occupancy_average_percent(indicate=\"UPSTREAM\")\n",
    "            flow_SB_UP,flow_WB_UP,flow_BIGC_UP = self.get_flow_sum(indicate=\"UPSTREAM\")\n",
    "            unjam_SB_UP,unjam_WB_UP,unjam_BIGC_UP = self.get_flow_sum(indicate=\"UPSTREAM\")\n",
    "\n",
    "            UPSTREAM_OBS = [occu_SB_UP,flow_SB_UP,unjam_SB_UP,\n",
    "                            occu_WB_UP,flow_WB_UP,unjam_WB_UP,\n",
    "                            occu_BIGC_UP,flow_BIGC_UP,unjam_BIGC_UP]\n",
    "\n",
    "            occu_SB_DOWN,occu_WB_DOWN,occu_BIGC_DOWN = self.get_occupancy_average_percent(indicate=\"DOWNSTREAM\")\n",
    "            flow_SB_DOWN,flow_WB_DOWN,flow_BIGC_DOWN = self.get_flow_sum(indicate=\"DOWNSTREAM\")\n",
    "            unjam_SB_DOWN,unjam_WB_DOWN,unjam_BIGC_DOWN = self.get_flow_sum(indicate=\"DOWNSTREAM\")\n",
    "\n",
    "            DOWNSTREAM_OBS = [occu_SB_DOWN,flow_SB_DOWN,unjam_SB_DOWN,\n",
    "                            occu_WB_DOWN,flow_WB_DOWN,unjam_WB_DOWN]   \n",
    "\n",
    "\n",
    "        observation = np.array(phase_id + min_green + UPSTREAM_OBS + DOWNSTREAM_OBS , dtype=np.float32)\n",
    "        # print(len(observation))\n",
    "        # print('------------------------------------------------------------------')\n",
    "        return observation\n",
    "            \n",
    "    def compute_reward(self):\n",
    "        self.last_reward = self._throughput_reward()\n",
    "        return self.last_reward\n",
    "\n",
    "    def compute_teleport(self):\n",
    "        self.last_teleport = traci.simulation.getEndingTeleportNumber()\n",
    "        return self.last_teleport\n",
    "\n",
    "\n",
    "    def _throughput_reward(self):\n",
    "        ####################### detectors for each intersection ######################################################\n",
    "        ONNUT_loopcoil = ['Induction_Loop_1','Induction_Loop_2','Induction_Loop_3',\n",
    "                          'Induction_Loop_4','Induction_Loop_5','Induction_Loop_6',\n",
    "                          'Induction_Loop_7','Induction_Loop_8','Induction_Loop_9','Induction_Loop_10']\n",
    "\n",
    "        VIRTUAL_loopcoil = [\n",
    "            \"Virtual_loop_1\",\"Virtual_loop_2\",\"Virtual_loop_3\",\n",
    "            \"Virtual_loop_4\",\"Virtual_loop_5\"]\n",
    "\n",
    "        if self.junction == 'VIRTUAL':\n",
    "            self.throughput = self.get_throughput(VIRTUAL_loopcoil)\n",
    "\n",
    "        elif self.junction == 'ONNUT':\n",
    "            self.throughput = self.get_throughput(ONNUT_loopcoil)\n",
    "\n",
    "        return self.throughput\n",
    "\n",
    "    def get_throughput(self,loopcoilIDs):\n",
    "        throughput = 0\n",
    "        for id in loopcoilIDs:\n",
    "\n",
    "            laneID = traci.inductionloop.getLaneID(id)\n",
    "            edgeID = traci.lane.getEdgeID(laneID)\n",
    "            speed = traci.edge.getLastStepMeanSpeed(edgeID)\n",
    "            if speed > 0:\n",
    "                throughput += traci.inductionloop.getLastStepVehicleNumber(id)\n",
    "\n",
    "        # # throughput = sum([traci.inductionloop.getLastStepVehicleNumber(i) for i in loopcoilIDs if traci.inductionloop.getLastStepMeanSpeed(i) > 0])\n",
    "        return throughput\n",
    "    ########################################################################\n",
    "    #\n",
    "    # getting attention places for each intersection\n",
    "    #\n",
    "    def get_observation_places(self):\n",
    "\n",
    "        Jvirtual = {\n",
    "            'SB_UPSTREAM' : [\n",
    "                            \"S_ONT_13_0\",\"S_ONT_13_1\",\n",
    "                            \"S_ONT_14_0\",\"S_ONT_14_1\",\n",
    "                            ],\n",
    "            'SB_DOWNSTREAM' : [\n",
    "                            \"S_ONT_15_0\",\"S_ONT_15_1\",\n",
    "                            \"S_ONT_16_0\",\"S_ONT_16_1\"\n",
    "                            ],\n",
    "            'WB_UPSTREAM' : [\n",
    "                \"S_ONT_02_0\",\"S_ONT_02_1\",\n",
    "                \"S_ONT_13_0\",\"S_ONT_13_1\",\n",
    "                \"S_ONT_14_0\",\"S_ONT_14_1\",\n",
    "                \"S_ONT_17_0\"\n",
    "            ],\n",
    "            'WB_DOWNSTREAM' : [\n",
    "                \"S_ONT_01_0\",\"S_ONT_01_1\",\n",
    "                \"S_ONT_15_0\",\"S_ONT_15_1\",\n",
    "                \"S_ONT_16_0\",\"S_ONT_16_1\"\n",
    "            ],\n",
    "\n",
    "            'BIGC_UPSTREAM' : [\"S_ONT_17_0\"],\n",
    "            # 'BIGC_DOWNSTREAM' : []\n",
    "        }\n",
    "\n",
    "        JOnnut = {\n",
    "                'SB_UPSTREAM' : [\n",
    "                    \"S_ONT_04_0\",\"S_ONT_04_1\",\"S_ONT_04_2\",\n",
    "                    \"S_ONT_09_0\",\"S_ONT_09_1\",\"S_ONT_09_2\"\n",
    "                ],\n",
    "                'SB_DOWNSTREAM' : [\"S_ONT_03_0\",\"S_ONT_03_1\",\"S_ONT_03_2\",\n",
    "                                   \"S_ONT_07_0\",\"S_ONT_07_1\",\"S_ONT_07_2\"],\n",
    "\n",
    "                'WB_UPSTREAM' : [\"S_ONT_05_0\",\"S_ONT_05_1\"],\n",
    "                'WB_DOWNSTREAM' : [\"S_ONT_18_0\",\"S_ONT_18_1\"],\n",
    "\n",
    "                'NB_UPSTREAM' : [\n",
    "                    \"S_ONT_06_0\",\"S_ONT_06_1\",\"S_ONT_06_2\",\"S_ONT_06_3\",\n",
    "                    \"S_ONT_11_0\",\"S_ONT_11_1\",\"S_ONT_11_2\",\"S_ONT_11_3\",\n",
    "                    \"S_ONT_12_0\",\"S_ONT_12_1\",\"S_ONT_12_2\",\"S_ONT_12_3\"\n",
    "                                ],\n",
    "                'NB_DOWNSTREAM' : [\n",
    "                    \"S_ONT_08_0\",\n",
    "                    \"S_ONT_10_0\",\"S_ONT_10_1\",\"S_ONT_10_2\"\n",
    "                ]\n",
    "                }\n",
    "\n",
    "        MAP = [Jvirtual, JOnnut]\n",
    "\n",
    "        state_places = None\n",
    "        if self.junction == 'ONNUT':\n",
    "            state_places = MAP[0]\n",
    "        elif self.junction == 'VIRTUAL':\n",
    "            state_places = MAP[1]\n",
    "\n",
    "        return len(state_places)\n",
    "\n",
    "    def get_flow_sum(self,indicate):\n",
    "        #     Speed (metres per sec) = flow (vehicle per sec) / density (veh per metre), Ajarn chaodit\n",
    "        #         flow= int(densityPerLane) * float(meanSpeed)#flow per lane\n",
    "        #     print('LastStepVehicleNumber', sum([traci.lanearea.getLastStepVehicleNumber(e) for e in detector_id]))\n",
    "        #     print('length', sum([traci.lanearea.getLength(i) for i in detector_id]))\n",
    "        #     density = sum([traci.lanearea.getLastStepVehicleNumber(e) for e in detector_id])/\\\n",
    "        #     sum([traci.lanearea.getLength(i) for i in detector_id])\n",
    "        #     print('density', density)\n",
    "        flow_SB = 0\n",
    "        flow_WB = 0\n",
    "        flow_OtherBound = 0\n",
    "        if indicate == \"UPSTREAM\" :\n",
    "            flow_SB = sum(([traci.lanearea.getLastStepVehicleNumber(e)*traci.lanearea.getLastStepMeanSpeed(e)/traci.lanearea.getLength(e)\n",
    "                            for e in self.SB_detectorID_dict['UPSTREAM'] if traci.lanearea.getLastStepMeanSpeed(e) >= 0]))\n",
    "            flow_WB = sum(([traci.lanearea.getLastStepVehicleNumber(e)*traci.lanearea.getLastStepMeanSpeed(e)/traci.lanearea.getLength(e)\n",
    "                            for e in self.WB_detectorID_dict['UPSTREAM'] if traci.lanearea.getLastStepMeanSpeed(e) >= 0]))\n",
    "\n",
    "            if self.junction == \"ONNUT\" :\n",
    "                #OtherBound = NB in ONNUT\n",
    "                flow_OtherBound = sum(([traci.lanearea.getLastStepVehicleNumber(e)*traci.lanearea.getLastStepMeanSpeed(e)/traci.lanearea.getLength(e)\n",
    "                                        for e in self.NB_detectorID_dict['UPSTREAM'] if traci.lanearea.getLastStepMeanSpeed(e) >= 0]))\n",
    "\n",
    "            elif self.junction == \"VIRTUAL\" :\n",
    "                #OtherBound = BIGC in onnut\n",
    "                flow_OtherBound = sum(([traci.lanearea.getLastStepVehicleNumber(e)*traci.lanearea.getLastStepMeanSpeed(e)/traci.lanearea.getLength(e)\n",
    "                                        for e in self.BIGC_detectorID_dict['UPSTREAM'] if traci.lanearea.getLastStepMeanSpeed(e) >= 0]))\n",
    "\n",
    "        elif indicate == \"DOWNSTREAM\" :\n",
    "\n",
    "            flow_SB = sum(([traci.lanearea.getLastStepVehicleNumber(e)*traci.lanearea.getLastStepMeanSpeed(e)/traci.lanearea.getLength(e)\n",
    "                            for e in self.SB_detectorID_dict[\"DOWNSTREAM\"] if traci.lanearea.getLastStepMeanSpeed(e) >= 0]))\n",
    "            flow_WB = sum(([traci.lanearea.getLastStepVehicleNumber(e)*traci.lanearea.getLastStepMeanSpeed(e)/traci.lanearea.getLength(e)\n",
    "                            for e in self.WB_detectorID_dict[\"DOWNSTREAM\"] if traci.lanearea.getLastStepMeanSpeed(e) >= 0]))\n",
    "\n",
    "            if self.junction == \"ONNUT\" :\n",
    "                #OtherBound = NB in ONNUT\n",
    "                flow_OtherBound = sum(([traci.lanearea.getLastStepVehicleNumber(e)*traci.lanearea.getLastStepMeanSpeed(e)/traci.lanearea.getLength(e)\n",
    "                                        for e in self.NB_detectorID_dict[\"DOWNSTREAM\"] if traci.lanearea.getLastStepMeanSpeed(e) >= 0]))\n",
    "\n",
    "            elif self.junction == \"VIRTUAL\" :\n",
    "                #OtherBound = BIGC in onnut\n",
    "                flow_OtherBound = sum(([traci.lanearea.getLastStepVehicleNumber(e)*traci.lanearea.getLastStepMeanSpeed(e)/traci.lanearea.getLength(e)\n",
    "                                        for e in self.BIGC_detectorID_dict[\"DOWNSTREAM\"] if traci.lanearea.getLastStepMeanSpeed(e) >= 0]))\n",
    "\n",
    "        return flow_SB, flow_WB, flow_OtherBound #OtherBound refer to different bound in onnut - virtual\n",
    "\n",
    "\n",
    "    def get_unjamlength_meters(self,indicate):\n",
    "        unjam_SB = 0\n",
    "        unjam_WB = 0\n",
    "        unjam_OtherBound = 0\n",
    "        if indicate == \"UPSTREAM\" :\n",
    "            detector_length = sum(traci.lanearea.getLength(d) for d in self.SB_detectorID_dict[\"UPSTREAM\"])\n",
    "            unjam_SB = detector_length - (sum([traci.lanearea.getJamLengthMeters(e) for e in self.SB_detectorID_dict[\"UPSTREAM\"]])) #/detector_length\n",
    "\n",
    "            detector_length = sum(traci.lanearea.getLength(d) for d in self.WB_detectorID_dict[\"UPSTREAM\"])\n",
    "            unjam_WB = detector_length - (sum([traci.lanearea.getJamLengthMeters(e) for e in self.WB_detectorID_dict[\"UPSTREAM\"]])) #/detector_length\n",
    "\n",
    "            if self.id == \"ONNUT\" :\n",
    "                #OtherBound = NB in ONNUT\n",
    "                detector_length = sum(traci.lanearea.getLength(d) for d in self.NB_detectorID_dict[\"UPSTREAM\"])\n",
    "                unjam_OtherBound = detector_length - (sum([traci.lanearea.getJamLengthMeters(e) for e in self.NB_detectorID_dict[\"UPSTREAM\"]])) #/detector_length\n",
    "\n",
    "            elif self.id == \"VIRTUAL\" :\n",
    "                #OtherBound = BIGC in onnut\n",
    "                detector_length = sum(traci.lanearea.getLength(d) for d in self.BIGC_detectorID_dict[\"UPSTREAM\"])\n",
    "                unjam_OtherBound = detector_length - (sum([traci.lanearea.getJamLengthMeters(e) for e in self.BIGC_detectorID_dict[\"UPSTREAM\"]])) #/detector_length\n",
    "\n",
    "        elif indicate == \"DOWNSTREAM\" :\n",
    "\n",
    "            detector_length = sum(traci.lanearea.getLength(d) for d in self.SB_detectorID_dict[\"DOWNSTREAM\"])\n",
    "            unjam_SB = detector_length - (sum([traci.lanearea.getJamLengthMeters(e) for e in self.SB_detectorID_dict[\"DOWNSTREAM\"]])) #/detector_length\n",
    "\n",
    "            detector_length = sum(traci.lanearea.getLength(d) for d in self.WB_detectorID_dict[\"DOWNSTREAM\"])\n",
    "            unjam_WB = detector_length - (sum([traci.lanearea.getJamLengthMeters(e) for e in self.WB_detectorID_dict[\"DOWNSTREAM\"]])) #/detector_length\n",
    "\n",
    "            if self.id == \"ONNUT\" :\n",
    "                #OtherBound = NB in ONNUT\n",
    "                detector_length = sum(traci.lanearea.getLength(d) for d in self.NB_detectorID_dict[\"DOWNSTREAM\"])\n",
    "                unjam_OtherBound = detector_length - (sum([traci.lanearea.getJamLengthMeters(e) for e in self.NB_detectorID_dict[\"DOWNSTREAM\"]])) #/detector_length\n",
    "\n",
    "            elif self.id == \"VIRTUAL\" :\n",
    "                #OtherBound = BIGC in onnut\n",
    "                detector_length = sum(traci.lanearea.getLength(d) for d in self.BIGC_detectorID_dict[\"DOWNSTREAM\"])\n",
    "                unjam_OtherBound = detector_length - (sum([traci.lanearea.getJamLengthMeters(e) for e in self.BIGC_detectorID_dict[\"DOWNSTREAM\"]])) #/detector_length\n",
    "\n",
    "        return unjam_SB, unjam_WB, unjam_OtherBound #OtherBound refer to different bound in onnut - virtual\n",
    "\n",
    "    def get_occupancy_average_percent(self,indicate):\n",
    "        #get occupancy average for all detector in detector_id and scale by (Vehicle Length + MinimumGap)/MinimumGap\n",
    "        #Vehicle Length = 4.62 MinimumGap = 2.37\n",
    "        occu_SB = 0\n",
    "        occu_WB = 0\n",
    "        occu_OtherBound = 0\n",
    "        if indicate == \"UPSTREAM\" :\n",
    "            occu_SB = (sum([traci.lanearea.getLastStepOccupancy(e) for e in self.SB_detectorID_dict['UPSTREAM']])\n",
    "                       /len(self.SB_detectorID_dict[\"UPSTREAM\"]))*((4.62+2.37)/4.62)\n",
    "            occu_WB = (sum([traci.lanearea.getLastStepOccupancy(e) for e in self.WB_detectorID_dict['UPSTREAM']])\n",
    "                       /len(self.WB_detectorID_dict[\"UPSTREAM\"]))*((4.62+2.37)/4.62)\n",
    "            if self.junction == \"ONNUT\" :\n",
    "                #OtherBound = NB in ONNUT\n",
    "                occu_OtherBound = (sum([traci.lanearea.getLastStepOccupancy(e) for e in self.NB_detectorID_dict['UPSTREAM']])\n",
    "                                   /len(self.NB_detectorID_dict[\"UPSTREAM\"]))*((4.62+2.37)/4.62)\n",
    "\n",
    "            elif self.junction == \"VIRTUAL\" :\n",
    "                #OtherBound = BIGC in onnut\n",
    "                occu_OtherBound = (sum([traci.lanearea.getLastStepOccupancy(e) for e in self.BIGC_detectorID_dict['UPSTREAM']])\n",
    "                                   /len(self.BIGC_detectorID_dict[\"UPSTREAM\"]))*((4.62+2.37)/4.62)\n",
    "\n",
    "        elif indicate == \"DOWNSTREAM\" :\n",
    "\n",
    "            occu_SB = (sum([traci.lanearea.getLastStepOccupancy(e) for e in self.SB_detectorID_dict[\"DOWNSTREAM\"]])\n",
    "                       /len(self.SB_detectorID_dict[\"UPSTREAM\"]))*((4.62+2.37)/4.62)\n",
    "\n",
    "            if len(self.WB_detectorID_dict[\"DOWNSTREAM\"]) == 0 :\n",
    "                occu_WB = 0\n",
    "            else :\n",
    "                occu_WB = (sum([traci.lanearea.getLastStepOccupancy(e) for e in self.WB_detectorID_dict[\"DOWNSTREAM\"]])\n",
    "                           /len(self.WB_detectorID_dict[\"DOWNSTREAM\"]))*((4.62+2.37)/4.62)\n",
    "            if self.junction == \"ONNUT\" :\n",
    "                #OtherBound = NB in ONNUT\n",
    "                occu_OtherBound = (sum([traci.lanearea.getLastStepOccupancy(e) for e in self.NB_detectorID_dict[\"DOWNSTREAM\"]])\n",
    "                                   /len(self.NB_detectorID_dict[\"DOWNSTREAM\"]))*((4.62+2.37)/4.62)\n",
    "\n",
    "            elif self.junction == \"VIRTUAL\" :\n",
    "                #OtherBound = BIGC in onnut\n",
    "                if len(self.BIGC_detectorID_dict[\"DOWNSTREAM\"]) == 0 :\n",
    "                    occu_OtherBound = 0\n",
    "                else :\n",
    "                    occu_OtherBound = (sum([traci.lanearea.getLastStepOccupancy(e) for e in self.BIGC_detectorID_dict[\"DOWNSTREAM\"]])\n",
    "                                       /len(self.BIGC_detectorID_dict[\"DOWNSTREAM\"]))*((4.62+2.37)/4.62)\n",
    "\n",
    "        return occu_SB, occu_WB, occu_OtherBound #OtherBound refer to different bound in onnut - virtual\n",
    "\n",
    "    def get_travel_time(self) :\n",
    "        # sum(traci.edge.getTraveltime(edgeID) for edgeID in self.edgeID_for_MOE)/len(self.edgeID_for_MOE)\n",
    "        if ((sum(traci.edge.getLastStepVehicleNumber(edgeID) for edgeID in self.edgeID_for_MOE)) != 0) : \n",
    "            travel_time = sum(traci.edge.getTraveltime(edgeID)*traci.edge.getLastStepVehicleNumber(edgeID) for edgeID in self.edgeID_for_MOE) \\\n",
    "                /(sum(traci.edge.getLastStepVehicleNumber(edgeID) for edgeID in self.edgeID_for_MOE) *len(self.edgeID_for_MOE))\n",
    "        else : \n",
    "            travel_time = 0\n",
    "        return travel_time\n",
    "    \n",
    "    # def get_travel_time_all(self) :\n",
    "    #     if ((sum(traci.edge.getLastStepVehicleNumber(edgeID) for edgeID in self.edgeID_all)) != 0) :\n",
    "    #         travel_time_all = sum(traci.edge.getTraveltime(edgeID)*traci.edge.getLastStepVehicleNumber(edgeID) for edgeID in self.edgeID_all) \\\n",
    "    #             /(sum(traci.edge.getLastStepVehicleNumber(edgeID) for edgeID in self.edgeID_all) *len(self.edgeID_all))\n",
    "    #     else :\n",
    "    #         travel_time_all = 0\n",
    "    #     return travel_time_all\n",
    "\n",
    "\n",
    "class maDQN:\n",
    "    def __init__(self,n_agents,num_actions,input_dims,learning_rate,gamma,env_name):\n",
    "        self.agents = {}\n",
    "        self.target_agents = {}\n",
    "        self.optimizers = []\n",
    "        self.n_agents = n_agents\n",
    "        self.gamma = gamma\n",
    "        self.env_name = env_name\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        for agent_idx in range(len(self.n_agents)):\n",
    "            self.agents[n_agents[agent_idx]]= Network(gamma, input_dims[agent_idx],num_actions[agent_idx])\n",
    "            self.agents[n_agents[agent_idx]].to(self.device)\n",
    "\n",
    "            self.target_agents[n_agents[agent_idx]] = Network(gamma,input_dims[agent_idx],num_actions[agent_idx])\n",
    "            self.target_agents[n_agents[agent_idx]].to(self.device)\n",
    "            self.target_agents[n_agents[agent_idx]].load_state_dict(self.agents[self.n_agents[agent_idx]].state_dict())\n",
    "            self.optimizers.append(torch.optim.Adam(self.agents[self.n_agents[agent_idx]].parameters(), lr=learning_rate))\n",
    "\n",
    "    def target_update(self):\n",
    "        for agent_idx in range(len(self.n_agents)):\n",
    "            self.target_agents[self.n_agents[agent_idx]].load_state_dict(self.agents[self.n_agents[agent_idx]].state_dict())\n",
    "\n",
    "\n",
    "    def save_checkpoint(self, score):\n",
    "        print('... saving checkpoint ...')\n",
    "        agent_save_paths = []\n",
    "        target_agent_save_paths = []\n",
    "\n",
    "        for i in range(len(self.n_agents)):\n",
    "            agent_save_paths.append('/pv/' +self.env_name + '/agent'+str(i)+'-score-{:.2f}.pack'.format(score)) \n",
    "            target_agent_save_paths.append('/pv/' +self.env_name + '/target-agent'+str(i)+'-score-{:.2f}.pack'.format(score)) \n",
    "\n",
    "        for agent_idx in range(len(self.n_agents)):\n",
    "            self.target_agents[self.n_agents[agent_idx]].load_state_dict(self.agents[self.n_agents[agent_idx]].state_dict())\n",
    "            self.agents[self.n_agents[agent_idx]].save(agent_save_paths[agent_idx])\n",
    "            self.target_agents[self.n_agents[agent_idx]].save(target_agent_save_paths[agent_idx])\n",
    "\n",
    "    def load_checkpoint(self,load_score):\n",
    "        print('... loading checkpoint ...')\n",
    "        for agent_idx in range(len(self.n_agents)):\n",
    "            path_a = '/pv/'+ self.env_name + '/agent' + str(agent_idx) + '-score-' + load_score + '.pack'\n",
    "            path_ta = '/pv/' + self.env_name + '/agent' + str(agent_idx) + '-score-' + load_score + '.pack'\n",
    "            self.agents[self.n_agents[agent_idx]].load(path_a)\n",
    "            self.target_agents[self.n_agents[agent_idx]].load(path_ta)\n",
    "\n",
    "    def choose_actions(self, raw_obs):\n",
    "        actions = []\n",
    "        for agent_idx, agent in self.agents.items():\n",
    "            action = agent.act(raw_obs[agent_idx])\n",
    "            actions.append(action)\n",
    "        return actions\n",
    "\n",
    "    def learn(self, batch):\n",
    "        for agent_idx in range(len(self.n_agents)):\n",
    "            agent_batch = batch[agent_idx]\n",
    "            loss = self.compute_loss(agent_batch,self.agents[self.n_agents[agent_idx]],self.target_agents[self.n_agents[agent_idx]])\n",
    "            # Gradient Descent\n",
    "            self.optimizers[agent_idx].zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizers[agent_idx].step()\n",
    "\n",
    "\n",
    "    def compute_loss(self, transitions, online_net, target_net):\n",
    "\n",
    "        transitions = pd.DataFrame(transitions).dropna().to_numpy()\n",
    "        \n",
    "        obses = np.asarray([t[0] for t in transitions],dtype=np.float32)\n",
    "        actions = np.asarray([t[1] for t in transitions],dtype=np.int64)\n",
    "        rews = np.asarray([t[2] for t in transitions],dtype=np.float32)\n",
    "        dones = np.asarray([t[3] for t in transitions],dtype=np.float32)\n",
    "        new_obses = np.asarray([t[4] for t in transitions],dtype=np.float32)\n",
    "\n",
    "        obses_t = torch.as_tensor(obses, dtype=torch.float32, device=self.device)\n",
    "        actions_t = torch.as_tensor(actions, dtype=torch.int64, device=self.device).unsqueeze(-1)\n",
    "        rews_t = torch.as_tensor(rews, dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        dones_t = torch.as_tensor(dones, dtype=torch.float32, device=self.device).unsqueeze(-1)\n",
    "        new_obses_t = torch.as_tensor(new_obses, dtype=torch.float32, device=self.device)\n",
    "\n",
    "        # Compute Targets\n",
    "        target_q_values = target_net(new_obses_t)\n",
    "        max_target_q_values = target_q_values.max(dim=1, keepdim=True)[0]\n",
    "        targets = rews_t + self.gamma * (1 - dones_t) * max_target_q_values\n",
    "\n",
    "        # Compute Loss\n",
    "        q_values = online_net(obses_t)\n",
    "        action_q_values = torch.gather(input=q_values, dim=1, index=actions_t)\n",
    "\n",
    "        loss = nn.functional.smooth_l1_loss(action_q_values, targets)\n",
    "        return loss\n",
    "\n",
    "# from torch import nn\n",
    "# import torch\n",
    "# import msgpack\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, gamma,input_dim, actions):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        self.net = nn.Sequential(\n",
    "                                nn.Linear(input_dim, 64),\n",
    "                                nn.Linear(64, actions))\n",
    "        named_layers = dict(self.net.named_modules())\n",
    "        # print(named_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def act(self, obs):\n",
    "        obs_t = torch.as_tensor(obs, dtype=torch.float32, device=self.device)\n",
    "        q_values = self(obs_t.unsqueeze(0))\n",
    "        max_q_index = torch.argmax(q_values, dim=1)[0]\n",
    "        action = max_q_index.detach().item()\n",
    "        return action\n",
    "\n",
    "    def save(self, save_path):\n",
    "        params = {k: t.detach().cpu().numpy() for k, t in self.state_dict().items()}\n",
    "        params_data = msgpack.dumps(params)\n",
    "        os.makedirs(os.path.dirname(save_path),exist_ok=True)\n",
    "        with open(save_path,'wb') as f:\n",
    "            f.write(params_data)\n",
    "\n",
    "    def load(self,load_path):\n",
    "        if not os.path.exists(load_path):\n",
    "            raise FileNotFoundError(load_path)\n",
    "        with open(load_path, 'rb') as f:\n",
    "            params_numpy = msgpack.loads(f.read())\n",
    "        params = {k: torch.as_tensor(v, device=self.device) for k,v in params_numpy.items()}\n",
    "\n",
    "        self.load_state_dict(params)\n",
    "#==================================== Main ==================================#\n",
    "\n",
    "\n",
    "#======== for confidence interval ========#\n",
    "# import random\n",
    "# random_seed = 0\n",
    "# random.seed(random_seed)\n",
    "#========================================#\n",
    "\n",
    "import msgpack\n",
    "import msgpack_numpy as m\n",
    "m.patch()\n",
    "\n",
    "ENV_NAME = 'onnut'\n",
    "\n",
    "N_EPISODES = 500 #1000\n",
    "MAX_STEPS = 960\n",
    "GAMMA=0.95\n",
    "BATCH_SIZE = 60\n",
    "BUFFER_SIZE=int(1000000)\n",
    "EPSILON_START= 1\n",
    "EPSILON_END=0.01\n",
    "EPSILON_DECAY= 10\n",
    "TARGET_UPDATE_FREQ = 60\n",
    "LR = 0.01\n",
    "PRINT_INTERVAL = 1\n",
    "TRAIN_INTERVAL = 10\n",
    "# TRAIN_INTERVAL = 2\n",
    "MOVING_AVERAGE = 960\n",
    "best_score = 1\n",
    "action_splits = []\n",
    "\n",
    "#==== max_green ====#\n",
    "max_green_ONNUT = 90\n",
    "max_green_VIRTUAL = 90\n",
    "\n",
    "env = SumoEnvironment(net_file='onnut.net.xml',\n",
    "                            single_agent=False,\n",
    "                            out_csv_name='/pv/outputs/onnut-dqn',\n",
    "                            use_gui=False,\n",
    "                            num_seconds=68400,\n",
    "                            yellow_time=0,\n",
    "                            min_green=15,\n",
    "                            max_green_onnut= max_green_ONNUT,\n",
    "                            max_green_virtual= max_green_VIRTUAL)\n",
    "\n",
    "for ts in env.ts_ids:\n",
    "    if isinstance(env.action_spaces(ts), gym.spaces.Discrete):\n",
    "        action_splits.append([env.action_spaces(ts).n]) # action_space.n means Discrete(3)\n",
    "    elif isinstance(env.action_spaces(ts), gym.spaces.MultiDiscrete):\n",
    "        action_splits.append(env.action_spaces(ts).nvec) # action_space.nvec means (3)\n",
    "\n",
    "n_actions_each = [sum(a) for a in action_splits]\n",
    "\n",
    "input_dims = []\n",
    "for ts in env.ts_ids:\n",
    "    input_dims.append(env.observation_spaces(ts).shape[0])\n",
    "\n",
    "maDQN_agents = maDQN(n_agents=list(env.traffic_signals.keys()), num_actions=n_actions_each, input_dims= input_dims,\n",
    "                         learning_rate=LR,\n",
    "                         gamma=GAMMA, env_name=ENV_NAME)\n",
    "\n",
    "replay_buffer = Buffer(n_agents=list(env.traffic_signals.keys()),buffer_size=BUFFER_SIZE,batch_size=BATCH_SIZE)\n",
    "\n",
    "score_history = []\n",
    "transition = {}\n",
    "# Main Training Loop\n",
    "for step in range(N_EPISODES):\n",
    "\n",
    "    #======== for confidence interval ========#\n",
    "    random_seed = step\n",
    "    random.seed(random_seed)\n",
    "    #========================================#\n",
    "\n",
    "    obs =  env.reset(random_seed)\n",
    "\n",
    "    done = [False]*3\n",
    "    episode_reward = 0\n",
    "    episode_step = 0\n",
    "    start_time = time.time()\n",
    "    epsilon = np.interp(step, [0, EPSILON_DECAY], [EPSILON_START, EPSILON_END])\n",
    "\n",
    "    if step >=TARGET_UPDATE_FREQ and step % TARGET_UPDATE_FREQ == 0:\n",
    "        maDQN_agents.target_update()\n",
    "\n",
    "    while not any(done):\n",
    "        rnd_sample = random.random()\n",
    "        if rnd_sample <= epsilon:\n",
    "            # actions = np.random.randint(0,N_ACTIONS,size=N_AGENTS)\n",
    "            action_onnut = random.randint(0,1)\n",
    "            action_virtual = random.randint(0,2)\n",
    "            actions = [action_onnut,action_virtual]\n",
    "        else:\n",
    "            actions = maDQN_agents.choose_actions(obs)\n",
    "\n",
    "\n",
    "        actions = dict(zip(env.traffic_signals.keys(), actions))\n",
    "        new_obs, rewards, done, _  = env.step(actions)\n",
    "        # transition = (obs, actions, rewards, dones, new_obs)\n",
    "        for ts in env.ts_ids:\n",
    "            transition[(ts, 'obs')] = obs[ts]\n",
    "            transition[(ts, 'actions')] = actions[ts]\n",
    "            transition[(ts, 'rewards')] = rewards[ts]\n",
    "            transition[(ts, 'dones')] = done[ts]\n",
    "            transition[(ts, 'new_obs')] = new_obs[ts]\n",
    "            replay_buffer.store(transition)\n",
    "\n",
    "        if episode_step >= MAX_STEPS:\n",
    "            done = [True] * 3\n",
    "        else:\n",
    "            done = list(done.values())\n",
    "        episode_step += 1\n",
    "\n",
    "        obs = new_obs\n",
    "        episode_reward += sum(rewards.values())\n",
    "\n",
    "        if step >= TRAIN_INTERVAL and  step % TRAIN_INTERVAL == 0:\n",
    "            batch = replay_buffer.sample()\n",
    "            maDQN_agents.learn(batch)\n",
    "\n",
    "    env.save_score()\n",
    "    score_history.append(episode_reward)\n",
    "\n",
    "    # Logging\n",
    "    if step >= PRINT_INTERVAL and step % PRINT_INTERVAL == 0:\n",
    "        avg_score = np.mean(score_history[-MOVING_AVERAGE:])\n",
    "        print('Step:', step)\n",
    "        print('Average Score: {:.2f}'.format(avg_score))\n",
    "        np.save('/pv/'+ENV_NAME+'score_history.npy',np.array(score_history))\n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            maDQN_agents.save_checkpoint(best_score)\n",
    "\n",
    "    elapsed_time = env.getTime((time.time() - start_time))\n",
    "    print('episode', step, ' takes time', elapsed_time)\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db24b9b7daf7499a4d4ebc1adaf7542ae49b05cdba3037987ac13500747b818e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('SeniorProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
